{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data_dir=\"data/split/\", n_files=25, epochs=1, ckpt_dir=\"ckpt/aunty\"):\n",
    "\n",
    "    file_order = list(range(1, n_files+1))\n",
    "\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.mkdir(ckpt_dir)\n",
    "    if not os.path.exists(utils.path_join(ckpt_dir, model.name)):\n",
    "        os.mkdir(utils.path_join(ckpt_dir, model.name))\n",
    "\n",
    "    checkpoints = [utils.path_join(ckpt_dir, model.name, name) for name in os.listdir(utils.path_join(ckpt_dir, model.name))]\n",
    "    if checkpoints:\n",
    "        latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "        print(\"Restoring from\", latest_checkpoint)\n",
    "        model = tf.keras.models.load_model(latest_checkpoint)\n",
    "        n = latest_checkpoint.split(\"-\")[-1][0]\n",
    "    else:\n",
    "        n = 0\n",
    "\n",
    "    processed_files = [filename.split(\".\")[0] for filename in os.listdir(utils.path_join(data_dir, \"processed\"))]\n",
    "    for file in file_order:\n",
    "        if file <= int(n):\n",
    "            continue\n",
    "        filename = f\"chess{file}\"\n",
    "        print(f\"Training on file {filename}\")\n",
    "\n",
    "        # load data from .csv file\n",
    "        if filename in processed_files:\n",
    "            df = pd.read_pickle(utils.path_join(data_dir, \"processed\", filename + \".pkl\"))\n",
    "        else:\n",
    "            df = pd.read_csv(utils.path_join(data_dir, filename + \".csv\"))\n",
    "\n",
    "            # translate from fen to obs arr\n",
    "            print(\"Processing...\", end=\"\")\n",
    "            df.loc[:, \"obs\"] = df.loc[:, \"board\"].map(utils.parse_fen)\n",
    "            print(\"complete\")\n",
    "\n",
    "        # convert to numpy arrays\n",
    "        x = {\n",
    "            \"board\": tf.keras.utils.to_categorical(np.array(df[\"obs_board\"].values.tolist()), num_classes=13), \n",
    "            \"misc\":np.array(df[\"obs_misc\"].values.tolist())\n",
    "        }\n",
    "        y = {\"ai\":df[\"move\"].values, \"aunty\":df[\"outcome\"].values}\n",
    "\n",
    "        # train\n",
    "        model.fit(x, y, batch_size=64, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "        # save checkpoint between files\n",
    "        model.save(utils.path_join(ckpt_dir, model.name, f\"{model.name}-{file}.h5\"))\n",
    "    print(f\"Training completed. Final save file: {utils.path_join(ckpt_dir, model.name, f'{model.name}-{file}.h5')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_names, data=\"validation\", data_dir=\"data/split/\", ckpt_dir=\"ckpt/aunty\", metric=\"binary_crossentropy\"):\n",
    "\n",
    "    models = []\n",
    "    for model_name in model_names:\n",
    "        checkpoints = [utils.path_join(ckpt_dir, model_name, name) for name in os.listdir(utils.path_join(ckpt_dir, model_name))]\n",
    "        if checkpoints:\n",
    "            latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "            print(\"Restoring from\", latest_checkpoint)\n",
    "            model = tf.keras.models.load_model(latest_checkpoint)\n",
    "            models.append(model)\n",
    "        else:\n",
    "            print(\"No checkpoint available\")\n",
    "\n",
    "    # load data\n",
    "    if data == \"validation\":\n",
    "        data = pd.read_csv(utils.path_join(data_dir, \"chess25.csv\"))\n",
    "    elif data == \"test\":\n",
    "        data = pd.read_csv(utils.path_join(data_dir, \"chess26.csv\"))\n",
    "    \n",
    "    # convert fen to obs\n",
    "    print(\"Processing...\", end=\"\")\n",
    "    data.loc[:, \"obs\"] = data.loc[:, \"board\"].map(utils.parse_fen)\n",
    "    print(\"complete\")\n",
    "\n",
    "    # convert to numpy arrays\n",
    "    x = np.array(data[\"obs\"].values.tolist())\n",
    "    y = data[\"outcome\"].values\n",
    "\n",
    "    performance = []\n",
    "    for model_name, model in zip(model_names, models):\n",
    "        performance.append([model_name, model.evaluate(x, y, batch_size=128, return_dict=True)[metric]])\n",
    "\n",
    "    return pd.DataFrame(performance, columns=[\"model_name\", metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "activation = \"relu\"\n",
    "board_input = tf.keras.Input(shape=(64, 13), name=\"board\")\n",
    "misc_input = tf.keras.Input(shape=(6), name=\"misc\")\n",
    "\n",
    "conv_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Reshape((8, 8, 13), input_shape=(64,13)),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=activation),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=activation),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=activation),\n",
    "    tf.keras.layers.MaxPool2D((2, 2),(1, 1), padding=\"same\"), \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256)\n",
    "], name=\"conv_model\")\n",
    "conv_output = conv_model(board_input)\n",
    "\n",
    "dense_inputs = tf.keras.layers.concatenate([conv_output, misc_input])\n",
    "aunty_model = tf.keras.models.Sequential([  # tf.concat([input[:1], conv_model_output, input[65:]], axis=0)\n",
    "    tf.keras.layers.Input(262),\n",
    "    tf.keras.layers.Dense(131, activation=activation),\n",
    "    tf.keras.layers.Dense(131, activation=activation),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "], name=\"aunty\")\n",
    "aunty_output = aunty_model(dense_inputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=[board_input, misc_input], outputs=aunty_output)\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss = {\"aunty\":tf.keras.losses.BinaryCrossentropy()},\n",
    "    metrics = {\"aunty\":tf.keras.metrics.BinaryCrossentropy()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15625/15625 [==============================] - 126s 8ms/step - loss: 5.5420 - ai_loss: 4.8890 - aunty_loss: 0.6531 - ai_sparse_categorical_accuracy: 0.1382 - aunty_binary_crossentropy: 0.6531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x303317880>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine both ai and aunty models into a single model with 2 outputs\n",
    "board_input = tf.keras.Input(shape=(64, 13), name=\"board\")\n",
    "misc_input = tf.keras.Input(shape=(6), name=\"misc\")\n",
    "x = {\"board\":obs_board, \"misc\":obs_misc}\n",
    "y = {\"ai\":df[\"move\"].values, \"aunty\":df[\"outcome\"].values}\n",
    "\n",
    "activation = \"relu\"\n",
    "conv_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Reshape((8, 8, 13), input_shape=(64,13)),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=activation),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=activation),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=activation),\n",
    "    tf.keras.layers.MaxPool2D((2, 2),(1, 1), padding=\"same\"), \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256)\n",
    "], name=\"conv_model\")\n",
    "conv_output = conv_model(board_input)\n",
    "\n",
    "dense_inputs = tf.keras.layers.concatenate([conv_output, misc_input])\n",
    "ai_model = tf.keras.models.Sequential([  # tf.concat([input[:1], conv_model_output, input[65:]], axis=0)\n",
    "    tf.keras.layers.Input(262),\n",
    "    tf.keras.layers.Dense(131, activation=activation),\n",
    "    tf.keras.layers.Dense(131, activation=activation),\n",
    "    tf.keras.layers.Dense(constants.LEN_UCI_MOVES, activation=\"softmax\")\n",
    "], name=\"ai\")\n",
    "ai_output = ai_model(dense_inputs)\n",
    "\n",
    "aunty_model = tf.keras.models.Sequential([  # tf.concat([input[:1], conv_model_output, input[65:]], axis=0)\n",
    "    tf.keras.layers.Input(262),\n",
    "    tf.keras.layers.Dense(131, activation=activation),\n",
    "    tf.keras.layers.Dense(131, activation=activation),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "], name=\"aunty\")\n",
    "aunty_output = aunty_model(dense_inputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=[board_input, misc_input], outputs=[ai_output, aunty_output])\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss = {\"aunty\":tf.keras.losses.BinaryCrossentropy(), \"ai\":tf.keras.losses.SparseCategoricalCrossentropy()},\n",
    "    metrics = {\"aunty\":tf.keras.metrics.BinaryCrossentropy(), \"ai\":tf.keras.metrics.SparseCategoricalAccuracy()},\n",
    ")\n",
    "\n",
    "model.fit(x, y, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit ('chess-ai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b6482292139e81a4c390b61f9abeeeb497a34aaede834f7065ff9959c827cc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
